##文本分类实例
###一般流程
1.首先去掉一些噪声，一般可用正则表达式检测并去掉，最好用空格做替代，为接下来的分词做准备，下面列举出常见噪声：
>网址，邮件，一些常见的网络添加的语言，譬如“我在这里”等等；
>标点符号（如果是做情感分析的，感叹号最好不要去掉）;
>年月分，时分秒，图片标识;

2.分词，这里我选用了哈工大的分词工具，具体命令可参考他们的[说明文档](http://ltp.readthedocs.io/zh_CN/latest/)。
3.分完词语之后，要去掉停用词，一般会有停用词表
4.去掉停用词之后，需要提取特征，对于文本而言TF-IDF，n-gram方法，LDA方法，word2vec等方法可以用来提取特征，用这些方法提取了特征之后，再用chi-sqaure，IG等方法选择特征。这里我们借用lucence里面的TF和IDF公式。对于特征k，有如下的公式：
$$TF_{k} = \sqrt{TF_{k}}$$
$$IDF_{k} = 1+log(\frac{NumOfDoc}{1+docFreq_{k}})$$
$$TFIDF=TF*IDF$$
关于chi-square方法和IG方法，另有两篇论文介绍。
&emsp;对于实际工程经验，我们需要了解到底层数据的需求，譬如对于TF数据，我们最好得到文档编号后就能获得相应的TF数据，这里我建议将TF数据做成等长的。对于IDF数据，我们输入一个特征，就能知道相应的文档编号及形成的数组。这样，我们就能定义这两个函数的接口了。这样做可以做到满足多种特征工程的需求。
>>TfHashPerDoc<Term, TermFreq> = getTfperDoc(DocIdx)
>>IdfDic<DocIdx[]> = getIdf(term)
>>dataList = {DocIdx, label}

5.SVM模型训练，这里主要说明下libsvm的输入输出格式。这种类别格式兼容蛮多软件格式的，譬如xgboost也是这种兼容格式，对于libsvm怎么用，具体类型，参数说明可以从libsvm的[主页](http://www.csie.ntu.edu.tw/~cjlin/libsvm/)查看到。
6.SVM模型优化，在libsvm程序中，提供一个SVM优化的程序，我们来说下这个程序，这个程序在libsvm/tools文件夹中，这个文件夹共有3个工具，具体的介绍在当前的README文件中都有，就不细说。

7.评估模型，

###实例说明
8.后话：一般分类的话，还有模型融合。